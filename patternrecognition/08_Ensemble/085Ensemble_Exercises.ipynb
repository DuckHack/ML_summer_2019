{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods. Exercises\n",
    "\n",
    "\n",
    "In this section we have only one exercise:\n",
    "\n",
    "1. Find the best three classifier in the stacking method using the classifiers from scikit-learn package, such as:\n",
    "\n",
    "\n",
    "* Linear regression,\n",
    "* Nearest Neighbors,\n",
    "* Linear SVM,\n",
    "* Decision Tree,\n",
    "* Naive Bayes,\n",
    "* QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data_set\n",
    "%store -r labels\n",
    "%store -r test_data_set\n",
    "%store -r test_labels\n",
    "%store -r unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Find the best three classifier in the stacking method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cl_list = [KNeighborsClassifier, DecisionTreeClassifier, GaussianNB, QuadraticDiscriminantAnalysis, SVC, LinearRegression]\n",
    "def build_classifiers():\n",
    "    classifiers = []\n",
    "    classifiers.append(KNeighborsClassifier())\n",
    "    classifiers.append(DecisionTreeClassifier())\n",
    "    classifiers.append(GaussianNB())\n",
    "    classifiers.append(QuadraticDiscriminantAnalysis())\n",
    "    classifiers.append(SVC(gamma='auto'))\n",
    "    classifiers.append(LinearRegression())\n",
    "    return classifiers\n",
    "    #return [classifier() for classifier in used_cl_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_classifier(classifiers, st_cl):\n",
    "    output = []\n",
    "    fitted_classifiers = [cl.fit(data_set, labels) for cl in classifiers]\n",
    "    for classifier in fitted_classifiers:\n",
    "        output.append(classifier.predict(data_set))\n",
    "    output = np.array(output).reshape((130,len(classifiers)))\n",
    "    \n",
    "    stacked_classifier = st_cl\n",
    "    stacked_classifier.fit(output.reshape((130,len(classifiers))), labels.reshape((130,)))\n",
    "    test_set = []\n",
    "    for classifier in fitted_classifiers:\n",
    "        test_set.append(classifier.predict(test_data_set))\n",
    "    test_set = np.array(test_set).reshape((len(test_set[0]),len(classifiers)))\n",
    "    predicted = stacked_classifier.predict(test_set)\n",
    "    #if stacked_classifier.__class__.__name__ == 'LinearRegression':\n",
    "    #print('stacked classifier name: ', st_cl.__class__.__name__)\n",
    "        #print('predicted:\\n', predicted, '\\n')\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyFiles\\anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\MyFiles\\anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\MyFiles\\anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\MyFiles\\anaconda\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "classifiers = build_classifiers()\n",
    "classifiers_batches = []\n",
    "for fst_idx in range(len(used_cl_list)):\n",
    "    for scd_idx in range(len(used_cl_list)):\n",
    "        if scd_idx < fst_idx:\n",
    "            continue\n",
    "        for thd_idx in range(len(used_cl_list)):\n",
    "            if fst_idx == scd_idx or scd_idx == thd_idx or thd_idx == fst_idx or classifiers[thd_idx].__class__.__name__ == 'LinearRegression':\n",
    "                continue\n",
    "            classifiers_batches.append([classifiers[fst_idx], classifiers[scd_idx], classifiers[thd_idx]])\n",
    "print( len(classifiers_batches) )\n",
    "\n",
    "for batch in classifiers_batches:\n",
    "    predicted.append(build_stacked_classifier(batch[:-1], batch[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   DecisionTreeClassifier   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   DecisionTreeClassifier   QuadraticDiscriminantAnalysis\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   GaussianNB   SVC\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   QuadraticDiscriminantAnalysis   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   QuadraticDiscriminantAnalysis   SVC\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   SVC   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  KNeighborsClassifier   LinearRegression   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  DecisionTreeClassifier   QuadraticDiscriminantAnalysis   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  DecisionTreeClassifier   QuadraticDiscriminantAnalysis   SVC\n",
      "Accuracy ->  1.0  for classifiers batch ->  DecisionTreeClassifier   SVC   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  GaussianNB   QuadraticDiscriminantAnalysis   SVC\n",
      "Accuracy ->  1.0  for classifiers batch ->  QuadraticDiscriminantAnalysis   SVC   GaussianNB\n",
      "Accuracy ->  1.0  for classifiers batch ->  QuadraticDiscriminantAnalysis   LinearRegression   GaussianNB\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, predicted[0])\n",
    "accuracies_list = [accuracy_score(test_labels, prediction) for prediction in predicted]\n",
    "for idx, acc in enumerate(accuracies_list):\n",
    "    if acc == np.max(accuracies_list):\n",
    "        fst_cl_name = classifiers_batches[idx][0].__class__.__name__\n",
    "        scd_cl_name = classifiers_batches[idx][1].__class__.__name__\n",
    "        thd_cl_name = classifiers_batches[idx][2].__class__.__name__\n",
    "        print('Accuracy -> ', acc, ' for classifiers batch -> ', fst_cl_name,' ',scd_cl_name,' ', thd_cl_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: \n",
    "\n",
    "Use the boosting method and change the code to fullfilt the following requirements:\n",
    "\n",
    "* the weights should be calculated as:\n",
    "$w_{n}^{(t+1)}=\\frac{1+ I(y_{n}\\neq h_{t}(x_{n}))}{\\sum_{i=1}^{N}1+I(y_{n}\\neq h_{t}(x_{n}))}$,\n",
    "* the prediction is done with a voting method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# prepare data set\n",
    "#I - calculate the accuracy vector\n",
    "\n",
    "def generate_data(sample_number, feature_number, label_number):\n",
    "    data_set = np.random.random_sample((sample_number, feature_number))\n",
    "    labels = np.random.choice(label_number, sample_number)\n",
    "    return data_set, labels\n",
    "\n",
    "labels = 2\n",
    "dimension = 2\n",
    "test_set_size = 1000\n",
    "train_set_size = 5000\n",
    "train_set, train_labels = generate_data(train_set_size, dimension, labels)\n",
    "test_set, test_labels = generate_data(test_set_size, dimension, labels)\n",
    "\n",
    "# init weights\n",
    "number_of_iterations = 10\n",
    "weights = np.ones((test_set_size,)) / test_set_size\n",
    "\n",
    "\n",
    "def train_model(classifier, weights):\n",
    "    return classifier.fit(X=test_set, y=test_labels, sample_weight=weights)\n",
    "\n",
    "def calculate_error(model):\n",
    "    predicted = model.predict(test_set)\n",
    "    I=calculate_accuracy_vector(predicted, test_labels)\n",
    "    Z=np.sum(I)\n",
    "    return (1+Z)/1.0\n",
    "\n",
    "def calculate_accuracy_vector(predicted, test_labels):\n",
    "    I = np.zeros(len(test_labels))\n",
    "    for idx, prediction in enumerate(predicted):\n",
    "        if prediction == test_labels[idx]:\n",
    "            I[idx] = 1\n",
    "    return I "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the two functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_new_weights(model):\n",
    "    predicted = model.predict(test_set)\n",
    "    return (np.ones(test_set_size)+calculate_accuracy_vector(predicted,test_labels))/sum(np.ones(test_set_size)+calculate_accuracy_vector(predicted,test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "classifier.fit(X=test_set, y=test_labels)\n",
    "alphas = []\n",
    "classifiers = []\n",
    "for iteration in range(number_of_iterations):\n",
    "    model = train_model(classifier, weights)\n",
    "    weights = set_new_weights(model)\n",
    "    classifiers.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_error(train_model(classifier, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the validation data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_x, validate_label = generate_data(1, dimension, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the prediction code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(x):\n",
    "    prediction_matrix = [classifier.predict(x) for classifier in classifiers] \n",
    "    if sum(prediction_matrix) <= number_of_iterations/2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45, 0.7, 0.45, 0.55, 0.65, 0.4, 0.75, 0.5, 0.45, 0.5, 0.5, 0.75, 0.4, 0.45, 0.35, 0.45, 0.5, 0.5, 0.6, 0.25, 0.5, 0.55, 0.45, 0.6, 0.5, 0.65, 0.6, 0.55, 0.55, 0.5, 0.5, 0.55, 0.55, 0.4, 0.6, 0.4, 0.35, 0.65, 0.75, 0.45, 0.4, 0.45, 0.75, 0.35, 0.5, 0.55, 0.45, 0.6, 0.45, 0.65, 0.45, 0.25, 0.5, 0.4, 0.7, 0.45, 0.5, 0.55, 0.6, 0.3, 0.55, 0.45, 0.6, 0.45, 0.4, 0.7, 0.5, 0.4, 0.6, 0.45, 0.65, 0.6, 0.45, 0.35, 0.35, 0.5, 0.55, 0.3, 0.45, 0.6, 0.45, 0.4, 0.65, 0.5, 0.45, 0.45, 0.45, 0.55, 0.5, 0.45, 0.5, 0.5, 0.65, 0.6, 0.55, 0.35, 0.55, 0.65, 0.55, 0.6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for j in range(100):\n",
    "    pred = []\n",
    "    val_labels = []\n",
    "    for i in range(20):\n",
    "        validate_x, validate_label = generate_data(1, dimension, labels)\n",
    "        prediction = get_prediction(validate_x)\n",
    "        pred.append(prediction)\n",
    "        val_labels.append(validate_label)\n",
    "    acc = accuracy_score(pred, val_labels)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "print(accuracies)\n",
    "plt.hist(accuracies) \n",
    "plt.plot()\n",
    "#Is there any sense in the random generated datasets+labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
